name: sloth_link_crawler
description: (WIP!) Web crawler to crawl all links of a website. Looking foward to respect robots.txt and use custom user agents.
version: 0.0.2
homepage: https://ynnob.com
repository: https://github.com/ynnob/sloth/tree/master/packages/sloth_link_crawler

environment:
  sdk: ">=2.18.6 <3.0.0"

dependencies:
  beautiful_soup_dart: ^0.3.0
  http: ^0.13.5
  http_interceptor: ^1.0.2
  queue: ^3.1.0+2
  robots_txt: ^1.1.1

dev_dependencies:
  lints: ^2.0.0
  test: ^1.16.0
